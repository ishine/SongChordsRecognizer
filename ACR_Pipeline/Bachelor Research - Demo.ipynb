{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bachelor Research - Demo.ipynb","provenance":[{"file_id":"1q0CBZvkEVnTFQFsuf7CEEwASvrA_aOnn","timestamp":1616363879529}],"collapsed_sections":["2ESDjHx946Jr"],"toc_visible":true,"authorship_tag":"ABX9TyNVTKIQ4WKcVl4jmXU7ozLl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2ESDjHx946Jr"},"source":["## Installations and Imports :\n","\n"]},{"cell_type":"code","metadata":{"id":"C1UdjUfD3j-7"},"source":["!pip install sklearn librosa tensorflow mir_eval"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5xfbSjrYxvCO","executionInfo":{"status":"ok","timestamp":1616537933934,"user_tz":-60,"elapsed":5053,"user":{"displayName":"Vojtech Lanz","photoUrl":"","userId":"15791523486540207166"}}},"source":["#!/usr/bin/env python3\n","import argparse\n","\n","from numpy.lib.npyio import save\n","from ACR_Training.Models import MLP, MLP_scalered, CRNN, CRNN_1, MLP2RNN, CRNN_2, BassVsThird\n","from ACR_Training.Datasets import IsophonicsDataset\n","from ACR_Training.SegmentationModels import SegmentationCRNN, EncoderDecoderSegmentation, colorize_spectrograms, chord_graphical_segmentations \n","import sklearn\n","import sys"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"JuTSQ3fN5s0g","executionInfo":{"status":"ok","timestamp":1616537933935,"user_tz":-60,"elapsed":5043,"user":{"displayName":"Vojtech Lanz","photoUrl":"","userId":"15791523486540207166"}}},"source":["#!/usr/bin/env python3\n","parser = argparse.ArgumentParser()\n","# Directories, destinations, folders, files\n","parser.add_argument(\"--isophonics_audio_directory\", default=\"./Datasets/Isophonics/AUDIO\", type=str, help=\"Path to ISOPHONICS directory with audio files.\")\n","parser.add_argument(\"--isophonics_annotations_directory\", default=\"./Datasets/Isophonics/ANNOTATIONS\", type=str, help=\"Path to ISOPHONICS directory with chord annotations.\")\n","parser.add_argument(\"--billboard_audio_directory\", default=\"./Datasets/Billboard/AUDIO\", type=str, help=\"Path to BILLBOARD directory with audio files.\")\n","parser.add_argument(\"--billboard_annotations_directory\", default=\"./Datasets/Billboard/ANNOTATIONS\", type=str, help=\"Path to BILLBOARD directory with chord annotations.\")\n","parser.add_argument(\"--isophonics_prep_dest\", default=\"./PreprocessedDatasets/isophonics_new.ds\", type=str, help=\"Preprocessed ISOPHONICS dataset destination.\")\n","parser.add_argument(\"--billboard_prep_dest\", default=\"./PreprocessedDatasets/billboard_new.ds\", type=str, help=\"Preprocessed BILLBOARD dataset destination.\")\n","\n","# Dataset preprocessing args\n","parser.add_argument(\"--dataset\", default=\"isophonics\", type=str, help=\"Dataset we want to preprocess, {isophonics, billboard}\")\n","#           Isophonics\n","parser.add_argument(\"--sample_rate\", default=44100, type=int, help=\"Sample rate for each song.\")\n","parser.add_argument(\"--hop_length\", default=512, type=int, help=\"10*(sample_rate/hop_length) is a number of miliseconds between two frames.\")\n","parser.add_argument(\"--window_size\", default=8, type=int, help=\"Spectrograms on left, and also spectrogram on right of the time bin -> window_size*2 + 1 spectrograms grouped together.\")\n","parser.add_argument(\"--flattened_window\", default=False, type=bool, help=\"Whether the spectrogram window should be flatten to one array or it sould be array of spectrograms.\")\n","parser.add_argument(\"--ms_intervals\", default=430.6640625, type=float, help=\"Miliseconds between generated spectrograms.\")\n","parser.add_argument(\"--to_skip\", default=10, type=int, help=\"How many spectrogram we want to skip when creating spectrogram window.\")\n","parser.add_argument(\"--norm_to_C\", default=True, type=bool, help=\"Whether we want to transpose all songs to C key (or D dorian, .. A minor, ...)\")\n","parser.add_argument(\"--spectrogram_type\", default=\"cqt\", type=str, help=\"Spectrogram types, {cqt,log_mel}\")\n","#           Billboard\n","parser.add_argument(\"--n_frames\", default=1000, type=int, help=\"Length of song subsequence we are consinder when predicting chords to keep some context.\")\n","\n","# Training args\n","parser.add_argument(\"--test_size\", default=0.3, type=lambda x:int(x) if x.isdigit() else float(x), help=\"Test set size.\")\n","parser.add_argument(\"--epochs\", default=100, type=int, help=\"Number of epochs.\")\n","parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\n","\n","\n","args = parser.parse_args([] if \"__file__\" not in globals() else None)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yizD2xg8i2o6"},"source":["# DEMO"]},{"cell_type":"code","metadata":{"id":"dFZkBI9Yi5iC","executionInfo":{"status":"ok","timestamp":1616537934522,"user_tz":-60,"elapsed":583,"user":{"displayName":"Vojtech Lanz","photoUrl":"","userId":"15791523486540207166"}}},"source":["import numpy as np\n","from ACR_Training.Models import MLP_scalered\n","from ACR_Training.Spectrograms import log_mel_spectrogram\n","from ACR_Pipeline.KeyRecognizer import KeyRecognizer\n","from ACR_Pipeline.DataPreprocessor import DataPreprocessor\n","from ACR_Pipeline.ChordVoter import ChordVoter\n","\n","def pipeline(waveform, sample_rate, hop_length, window_size, spectrogram_type):\n","\n","    # Load models\n","    basic_mlp = MLP_scalered.load('./ACR_Pipeline/models/basic_mlp.model')\n","    C_transposed_mlp = MLP_scalered.load('./ACR_Pipeline/models/C_transposed_mlp.model')\n","\n","\n","\n","    # Preprocess Data\n","    x = DataPreprocessor.flatten_preprocess(\n","        waveform=waveform,\n","        sample_rate=sample_rate,\n","        hop_length=hop_length,\n","        window_size=window_size,\n","        spectrogram_generator=spectrogram_type,\n","        norm_to_C=False\n","    )\n","\n","    # Get list of played chords\n","    baisc_chord_prediction = basic_mlp.predict(x)\n","    chords, counts = np.unique(baisc_chord_prediction, return_counts=True)\n","    chord_counts = dict(zip(chords, counts))\n","\n","    # Get song's key (not really tonic, A minor/ailoian is same as a C major or D dorian)\n","    key = KeyRecognizer.estimate_key(chord_counts)\n","\n","    # Tranapose Song to a C major\n","    x_transposed = DataPreprocessor.flatten_preprocess(\n","        waveform=waveform,\n","        sample_rate=sample_rate,\n","        hop_length=hop_length,\n","        window_size=window_size,\n","        spectrogram_generator=spectrogram_type,\n","        norm_to_C=True,\n","        key=key\n","    )\n","\n","    # Get chord sequence of a song\n","    transposed_chord_prediction = C_transposed_mlp.predict(x_transposed)\n","\n","    # Chord voting for each beat\n","    chord_sequence = ChordVoter.vote_for_beats(\n","        chord_sequence=transposed_chord_prediction,\n","        waveform=waveform, sample_rate=sample_rate,\n","        hop_length=hop_length\n","    )\n","\n","    # Transpose to the original sequence\n","    original_chord_sequence = DataPreprocessor.transpose(\n","        chord_sequence=chord_sequence, \n","        from_key = 'C', \n","        to_key = key\n","    )\n","\n","    return DataPreprocessor.chord_indices_to_notations(original_chord_sequence)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gDIsM3Y4l7LR","executionInfo":{"status":"ok","timestamp":1616537970521,"user_tz":-60,"elapsed":13242,"user":{"displayName":"Vojtech Lanz","photoUrl":"","userId":"15791523486540207166"}},"outputId":"75791e6e-63f6-4ff6-b9d4-fcc8663fd582"},"source":["import librosa\n","from ACR_Training.Spectrograms import log_mel_spectrogram\n","# Load audio\n","y, sr = librosa.load('Help!.wav', 44100)\n","\n","# Predict chords\n","sequence = pipeline(\n","    waveform=y,\n","    sample_rate=sr,\n","    hop_length=22050,\n","    window_size=5,\n","    spectrogram_type=log_mel_spectrogram\n",")\n","print()\n","print()\n","print(sequence)\n","print()\n","print()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/librosa/filters.py:239: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n","  \"Empty filters detected in mel frequency basis. \"\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","['A', 'A', 'A', 'A', 'A', 'A', 'B:min', 'B:min', 'B:min', 'A', 'B:min', 'B:min', 'A', 'A', 'A', 'A', 'B:min', 'A', 'A', 'B:min', 'A', 'A', 'A', 'A', 'A', 'B:min', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B:min', 'B:min', 'A', 'A', 'B:min', 'B:min', 'A', 'A', 'A', 'B:min', 'B:min', 'B:min', 'B:min', 'A', 'A', 'A', 'A', 'A', 'A', 'B:min', 'B:min', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B:min', 'A', 'A', 'A', 'A', 'B:min', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B:min', 'A', 'A', 'A', 'A', 'B:min', 'A', 'A', 'A', 'B:min', 'A', 'A', 'B:min', 'B:min', 'A', 'A', 'B:min', 'B:min', 'A', 'A', 'B:min', 'B:min', 'A', 'A', 'B:min', 'A', 'A', 'B:min', 'B:min', 'A', 'A', 'A', 'B:min', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B:min', 'A', 'B:min', 'A', 'B:min']\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/librosa/filters.py:239: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n","  \"Empty filters detected in mel frequency basis. \"\n"],"name":"stderr"}]}]}